# 20191226

## 1. 讲座: deep learning for  semantic segmentation

华科phd: 余昌黔

记录者: JimmyJiao

### 1) semantic(语义) segmentation(分割, 需要做localization) review

目标: label -> each single pixel.

1. 视觉常见任务: 分割, 分类+定义, 物体识别, instance segmentation(可属的进行分类)

分割和instance segmentation进行分割.

2. 常用的数据集

   pascal voc等

### 2) high accuracy methods

1. FCN pixels in, pixels out

2. 文章分类(从localization的角度, 和classification的角度)

   讲座亮点: 图片+highlight

   #### 2.1) localization view

   FCN-8s: FCN, conv?原先模糊输出,跨层链接,输出更加细致

   U-Net: 医学图像: encoder-Decoder

   SegNet: encoder-decoder, pooling方法, average pooling等....恢复一些信息

   deconvNet:unpooling, deconvolution

   RefineNet: RCU: residual conv Unit-> mutli-resolution fusion->chained residual polling,(当时效果还不错)

   LRR: laplacian ryramid reconstruction and refinement: high level的边界提取, 帮助low level的边界提取, 然后加在一起. 
   
   CRFasRNN:conditional random fields 自动去学, mean-field to approximate the CRF, CRF for structured prediction.
   
   SegModel: context CRF, guidance CRF(优化细节)
   
   ### # 2.2)classification view
   
   deeplab: 解决感受野变小的问题, dilation conv (enlarge receptive field) 在目前深度学习经常使用
   
   DUC(dense upsampling convolution): follow上面的 dialation conv, 有些网格采样方法改进, 防止信息丢失. hybrid dilated convolution-> address the gridding issue
   
   GCN(global convolutional network)与dialation conv一样进行扩大感受野, 更大的卷积.large kernel convolution.
   
   PSPNet 常用的分割网络 CNN->dialation conv-> global conv pooling:  pyramid pooling
   
   Deeplab v3: 
   
   encNet: context encoding module, semantic encoding loss 聚类中心.reweight.**(画图)**
   
   deeplab v3+ 目前最好的方法之一 combine multi-scale context and .
   
   
   
3. 本次

   1) motivation

intra -class  inconsistency类中的不一致性, 类间的低区分性.->discriminative feature network

​	2) border network + smooth network

smooth network 类的不一致性的解决: a) 宏观理解mulit-scale and global context b) selection 

border network: semantic boundary to guide feature learning来帮助类间的学习.

​	3) object context network: scene+stuff的学习

​	4) high-efficiency methods linknet(encoder,decoder)   

​	5) github repo: TorchSeg

   

## 3) 问题

1.feature提取从哪里来的?

2.为什么要downsample?图像很大,速度过慢. encoder其实是为了downsample.

3.loss函数: 没有听清楚.

4.pooling以前是网络不好所以会使用,现在不需要.

5.什么叫backbone?一个共享结构。
 概念中提到，它是Object Detection, Scene Parsing, OCR等任务的前导性任务。

经典基础结构总结: https://blog.csdn.net/kuweicai/article/details/102789420

请见:  https://blog.csdn.net/baishuo8/article/details/89926028

```
AlexNet: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
VGG: https://arxiv.org/pdf/1409.1556.pdf
GoogleNet: https://arxiv.org/pdf/1409.4842.pdf
Compact Bilinear: https://arxiv.org/pdf/1511.06062.pdf
Residual Network: https://arxiv.org/pdf/1512.03385.pdf
Inception: https://arxiv.org/pdf/1602.07261.pdf
Wide ResNet: https://arxiv.org/pdf/1605.07146.pdf
FractalNet: https://arxiv.org/pdf/1605.07648.pdf
DenseNet: https://arxiv.org/pdf/1608.06993.pdf
ResNeXt: https://arxiv.org/pdf/1611.05431.pdf
SORT: https://arxiv.org/pdf/1703.06993.pdf
```

6.三个一起train -> 性能

7.深度学习的缺陷: data 驱动, 需要很大的算力, 

8.分割可以用在美颜, 无人驾驶等等.